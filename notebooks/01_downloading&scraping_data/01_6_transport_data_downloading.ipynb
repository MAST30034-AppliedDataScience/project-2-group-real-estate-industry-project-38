{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "domain_data_dir = '../../data/landing/other_data'\n",
    "os.makedirs(domain_data_dir, exist_ok=True)  # Create the folder if it doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://data.ptv.vic.gov.au/downloads/gtfs.zip'\n",
    "response = requests.get(url)\n",
    "\n",
    "with zipfile.ZipFile(io.BytesIO(response.content)) as the_zip:\n",
    "    the_zip.extractall('../../data/landing/other_data/stops_datavic')\n",
    "\n",
    "extracted_folder_path = '../../data/landing/other_data/stops_datavic'\n",
    "for root, dirs, files in os.walk(extracted_folder_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.zip'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(root)\n",
    "\n",
    "stops_files = []\n",
    "for root, dirs, files in os.walk(extracted_folder_path):\n",
    "    for file in files:\n",
    "        if file == 'stops.txt':\n",
    "            file_path = os.path.join(root, file)\n",
    "            df = pd.read_csv(file_path)\n",
    "            stops_files.append(df)\n",
    "\n",
    "combined_stops_df = pd.concat(stops_files, ignore_index=True)\n",
    "\n",
    "stops_data_dir = '../../data/raw/stops_data'\n",
    "os.makedirs(stops_data_dir, exist_ok=True)  # Create the folder if it doesn't exist\n",
    "\n",
    "output_csv_path = os.path.join(stops_data_dir, 'stops_datavic.csv')\n",
    "combined_stops_df.to_csv(output_csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows deleted due to duplicate stop_id: 507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8_/gylgnm051zv9rk4m5lzq6c880000gn/T/ipykernel_14718/158890845.py:22: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: None\n",
      "Right CRS: EPSG:7844\n",
      "\n",
      "  stops_in_regions = gpd.sjoin(stops_gdf, regions_gdf, how='left', predicate='within')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train station count: 559\n",
      "Tram station count: 2020\n",
      "Bus station count: 25237\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import re\n",
    "\n",
    "def process_stops_csv(input_csv, output_csv, regions_geojson):\n",
    "\n",
    "    df = pd.read_csv(input_csv)\n",
    "    \n",
    "    before_count = len(df)\n",
    "    df = df.drop_duplicates(subset=['stop_id'])\n",
    "    after_count = len(df)\n",
    "    deleted_count = before_count - after_count\n",
    "    \n",
    "    print(f\"Number of rows deleted due to duplicate stop_id: {deleted_count}\")\n",
    "    \n",
    "    geometry = [Point(xy) for xy in zip(df['stop_lon'], df['stop_lat'])]\n",
    "    stops_gdf = gpd.GeoDataFrame(df, geometry=geometry)\n",
    "    \n",
    "    regions_gdf = gpd.read_file(regions_geojson)\n",
    "    \n",
    "    stops_in_regions = gpd.sjoin(stops_gdf, regions_gdf, how='left', predicate='within')\n",
    "    \n",
    "    stops_in_regions['region'] = stops_in_regions['SA2_NAME21']  \n",
    "    \n",
    "    stops_in_regions = stops_in_regions.drop(columns=['index_right', 'geometry'])\n",
    "    \n",
    "    def determine_stop_type(stop_name):\n",
    "        if 'railway station' in stop_name.lower():\n",
    "            return 'train station'\n",
    "        elif re.match(r'^\\d', stop_name):\n",
    "            return 'tram station'\n",
    "        else:\n",
    "            return 'bus station'\n",
    "    \n",
    "    stops_in_regions['stop_type'] = stops_in_regions['stop_name'].apply(determine_stop_type)\n",
    "    \n",
    "    station_counts = stops_in_regions['stop_type'].value_counts()\n",
    "    \n",
    "    print(f\"Train station count: {station_counts.get('train station', 0)}\")\n",
    "    print(f\"Tram station count: {station_counts.get('tram station', 0)}\")\n",
    "    print(f\"Bus station count: {station_counts.get('bus station', 0)}\")\n",
    "    \n",
    "    stops_in_regions.to_csv(output_csv, index=False)\n",
    "    \n",
    "    return deleted_count, station_counts\n",
    "\n",
    "input_csv = '../../data/raw/stops_data/stops_datavic.csv'\n",
    "output_csv = '../../data/raw/stops_data/stops_datavic_mapped.csv'\n",
    "regions_geojson = '../../data/landing/region_data/sa2_dataset/sa2_unzip'\n",
    "\n",
    "deleted_rows, station_counts = process_stops_csv(input_csv, output_csv, regions_geojson)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
