{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openrouteservice import Client\n",
    "from sklearn.neighbors import BallTree\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_df = pd.read_csv(\"../../data/raw/stops_data/stops_datavic_mapped.csv\")\n",
    "property_df = pd.read_csv(\"../../data/curated/properties_data3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_five_university =  pd.read_csv('../../data/landing/osm_data/top_five_university_main_campus.csv')\n",
    "entertainments_df = pd.read_csv('../../data/raw/osm_data/entertainments.csv')\n",
    "hospital_df = pd.read_csv('../../data/raw/osm_data/hospital.csv')\n",
    "park_df = pd.read_csv('../../data/raw/osm_data/park.csv')\n",
    "psf_df = pd.read_csv('../../data/raw/osm_data/psf.csv')\n",
    "school1_df = pd.read_csv('../../data/raw/osm_data/school1.csv')\n",
    "school2_df = pd.read_csv('../../data/raw/osm_data/school2.csv')\n",
    "shop_df = pd.read_csv('../../data/raw/osm_data/shop.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Property DataFrame:\n",
      "latitude     0\n",
      "longitude    0\n",
      "dtype: int64\n",
      "\n",
      "Stations DataFrame:\n",
      "stop_lat    0\n",
      "stop_lon    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Property DataFrame:\")\n",
    "print(property_df[['latitude', 'longitude']].isnull().sum())\n",
    "\n",
    "print(\"\\nStations DataFrame:\")\n",
    "print(stations_df[['stop_lat', 'stop_lon']].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert latitude and longitude columns in both DataFrames to float for accurate calculations.\n",
    "property_df['latitude'] = property_df['latitude'].astype(float)\n",
    "property_df['longitude'] = property_df['longitude'].astype(float)\n",
    "\n",
    "stations_df['stop_lat'] = stations_df['stop_lat'].astype(float)\n",
    "stations_df['stop_lon'] = stations_df['stop_lon'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename latitude and longitude columns in 'stations_df' and filter for rows where 'stop_type' is 'train station'.\n",
    "stations_df.rename(columns={'stop_lat': 'latitude', 'stop_lon': 'longitude'}, inplace=True)\n",
    "train_stations_df = stations_df[stations_df['stop_type'] == 'train station']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate 'name' values: 0\n"
     ]
    }
   ],
   "source": [
    "# Count and print the number of duplicate 'property_url' values in the 'property_df'\n",
    "_duplicates = property_df['property_url'].duplicated(keep=\"first\").sum()\n",
    "print(f\"Number of duplicate 'name' values: {_duplicates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Enginnering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance and Duration to the Closet Train Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# client = Client(key='5b3ce3597851110001cf6248a027188a61b345eeb77761e0521405ba')\n",
    "# If API key exceeds the quota, try uncomment and run the line above and comment the line below.\n",
    "client = Client(key='5b3ce3597851110001cf62489c86d07e1db14afbbf6fece88bfe6afe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the latitude and longitude values of train stations and properties from degrees to radians \n",
    "train_stations_coords = np.deg2rad(train_stations_df[['latitude', 'longitude']].values)\n",
    "properties_coords = np.deg2rad(property_df[['latitude', 'longitude']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a BallTree using the Haversine distance metric to find the nearest train station for each property.\n",
    "# Convert the distances from radians to meters, then assign the nearest station index and distance to the properties.\n",
    "# Add coordinates of both the property and the nearest station, along with the station's name, to the DataFrame.\n",
    "\n",
    "tree = BallTree(train_stations_coords, metric='haversine')\n",
    "distances, indices = tree.query(properties_coords, k=1)\n",
    "\n",
    "earth_radius = 6371000 \n",
    "distances_m = distances.flatten() * earth_radius\n",
    "\n",
    "nearest_station_indices = indices.flatten()\n",
    "\n",
    "property_df['nearest_station_index'] = nearest_station_indices\n",
    "property_df['haversine_distance'] = distances_m\n",
    "\n",
    "property_df['property_coords'] = property_df.apply(lambda row: [row['longitude'], row['latitude']], axis=1)\n",
    "property_df['station_coords'] = property_df['nearest_station_index'].apply(\n",
    "    lambda idx: [train_stations_df.iloc[idx]['longitude'], train_stations_df.iloc[idx]['latitude']]\n",
    ")\n",
    "\n",
    "property_df['nearest_station_name'] = property_df['nearest_station_index'].apply(\n",
    "    lambda idx: train_stations_df.iloc[idx]['stop_name']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert property and station coordinates into lists of origin and destination points for further analysis.\n",
    "origins = property_df['property_coords'].tolist()\n",
    "destinations = property_df['station_coords'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization & limitation\n",
    "max_elements = 2500 \n",
    "max_locations = 50  \n",
    "results = []\n",
    "num_properties = len(origins)\n",
    "chunk_size = max_locations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing properties 0 to 49\n",
      "Processing properties 50 to 99\n",
      "Processing properties 100 to 149\n",
      "Processing properties 150 to 199\n",
      "Processing properties 200 to 249\n",
      "Processing properties 250 to 299\n",
      "Processing properties 300 to 349\n",
      "Processing properties 350 to 399\n",
      "Processing properties 400 to 449\n",
      "Processing properties 450 to 499\n",
      "Processing properties 500 to 549\n",
      "Processing properties 550 to 599\n",
      "Processing properties 600 to 649\n",
      "Processing properties 650 to 699\n",
      "Processing properties 700 to 749\n",
      "Processing properties 750 to 799\n",
      "Processing properties 800 to 849\n",
      "Processing properties 850 to 899\n",
      "Processing properties 900 to 949\n",
      "Processing properties 950 to 999\n",
      "Processing properties 1000 to 1049\n",
      "Processing properties 1050 to 1099\n",
      "Processing properties 1100 to 1149\n",
      "Processing properties 1150 to 1199\n",
      "Processing properties 1200 to 1249\n",
      "Processing properties 1250 to 1299\n",
      "Processing properties 1300 to 1349\n",
      "Processing properties 1350 to 1399\n",
      "Processing properties 1400 to 1449\n",
      "Processing properties 1450 to 1499\n",
      "Processing properties 1500 to 1549\n",
      "Processing properties 1550 to 1599\n",
      "Processing properties 1600 to 1649\n",
      "Processing properties 1650 to 1699\n",
      "Processing properties 1700 to 1749\n",
      "Processing properties 1750 to 1799\n",
      "Processing properties 1800 to 1849\n",
      "Processing properties 1850 to 1899\n",
      "Processing properties 1900 to 1949\n",
      "Processing properties 1950 to 1999\n",
      "Processing properties 2000 to 2049\n",
      "Processing properties 2050 to 2099\n",
      "Processing properties 2100 to 2149\n",
      "Processing properties 2150 to 2199\n",
      "Processing properties 2200 to 2249\n",
      "Processing properties 2250 to 2299\n",
      "Processing properties 2300 to 2349\n",
      "Processing properties 2350 to 2399\n",
      "Processing properties 2400 to 2449\n",
      "Processing properties 2450 to 2499\n",
      "Processing properties 2500 to 2549\n",
      "Processing properties 2550 to 2599\n",
      "Processing properties 2600 to 2649\n",
      "Processing properties 2650 to 2699\n",
      "Processing properties 2700 to 2749\n",
      "Processing properties 2750 to 2799\n",
      "Processing properties 2800 to 2842\n"
     ]
    }
   ],
   "source": [
    "# Process properties in chunks, sending batches of origins and destinations to the API to get distance and duration.\n",
    "# For each chunk, the distance matrix is calculated using the driving-car, and results are stored.\n",
    "for i in range(0, num_properties, chunk_size):\n",
    "    origin_chunk = origins[i:i+chunk_size]\n",
    "    destination_chunk = destinations[i:i+chunk_size]\n",
    "\n",
    "    if len(destination_chunk) > len(origin_chunk):\n",
    "        destination_chunk = destination_chunk[:len(origin_chunk)]\n",
    "\n",
    "    print(f\"Processing properties {i} to {i + len(origin_chunk) - 1}\")\n",
    "\n",
    "    try:\n",
    "        matrix = client.distance_matrix(\n",
    "            locations=origin_chunk + destination_chunk,\n",
    "            sources=list(range(len(origin_chunk))),\n",
    "            destinations=list(range(len(origin_chunk), len(origin_chunk) + len(destination_chunk))),\n",
    "            profile='driving-car',\n",
    "            metrics=['distance', 'duration'],\n",
    "            resolve_locations=False,\n",
    "            units='m'\n",
    "        )\n",
    "\n",
    "        distances = matrix['distances']\n",
    "        durations = matrix['durations']\n",
    "\n",
    "        for j in range(len(origin_chunk)):\n",
    "            distance = distances[j][j]\n",
    "            duration = durations[j][j]\n",
    "            results.append({\n",
    "                'property_index': property_df.index[i + j],\n",
    "                'route_distance_m': distance,\n",
    "                'route_duration_s': duration\n",
    "            })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch {i} to {i + len(origin_chunk) - 1}: {e}\")\n",
    "        for j in range(len(origin_chunk)):\n",
    "            results.append({\n",
    "                'property_index': property_df.index[i + j],\n",
    "                'route_distance_m': None,\n",
    "                'route_duration_s': None\n",
    "            })\n",
    "\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "property_df = property_df.merge(df_results, left_index=True, right_on='property_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance to the Closet Hosptial/Fire Station/Police Station/University and College/Shop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function computes the nearest external location for a given set of property coordinates.\n",
    "# It converts the external coordinates to radians, builds a BallTree using the Haversine metric, \n",
    "# and finds the closest match in terms of distance and name. The function returns the distances in meters \n",
    "# and the names of the nearest external locations.\n",
    "def compute_nearest_distance_and_name(property_coords_rad, external_coords, external_names):\n",
    "    external_coords_rad = np.deg2rad(external_coords)\n",
    "    tree = BallTree(external_coords_rad, metric='haversine')\n",
    "    distances, indices = tree.query(property_coords_rad, k=1)\n",
    "    nearest_names = external_names[indices.flatten()]\n",
    "    return distances.flatten() * earth_radius, nearest_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function calculates the distances from each property to the five nearest external locations.\n",
    "# It uses the Haversine metric in a BallTree to compute the distances in kilometers and returns both\n",
    "# the distances and the names of the nearest external locations.\n",
    "def compute_all_distances(property_coords_rad, external_coords_rad, external_names):\n",
    "    tree = BallTree(external_coords_rad, metric='haversine')\n",
    "    distances, indices = tree.query(property_coords_rad, k=5)\n",
    "    distances_km = distances * earth_radius\n",
    "    names = external_names[indices]\n",
    "    return distances_km, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "police_stations_df = psf_df[psf_df['amenity'] == 'police']\n",
    "fire_stations_df = psf_df[psf_df['amenity'] == 'fire_station']\n",
    "university_college_df = school2_df[school2_df['amenity'] != \"kindergarten\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hospital\n",
    "hospital_coords = hospital_df[['lat', 'lon']].values\n",
    "hospital_names = hospital_df['name'].values\n",
    "property_df['distance_to_hospital'], property_df['nearest_hospital_name'] = compute_nearest_distance_and_name(\n",
    "    properties_coords, hospital_coords, hospital_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Police Station\n",
    "police_station_coords = police_stations_df[['lat', 'lon']].values\n",
    "police_station_names = police_stations_df['name'].values\n",
    "property_df['distance_to_police_station'], property_df['nearest_police_station_name'] = compute_nearest_distance_and_name(\n",
    "    properties_coords, police_station_coords, police_station_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fire Station\n",
    "fire_station_coords = fire_stations_df[['lat', 'lon']].values\n",
    "fire_station_names = fire_stations_df['name'].values\n",
    "property_df['distance_to_fire_station'], property_df['nearest_fire_station_name'] = compute_nearest_distance_and_name(\n",
    "    properties_coords, fire_station_coords, fire_station_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# college/University\n",
    "university_college_coords = university_college_df[['lat', 'lon']].values\n",
    "university_college_names = university_college_df['name'].values\n",
    "property_df['distance_to_university_college'], property_df['nearest_university_college_name'] = compute_nearest_distance_and_name(\n",
    "    properties_coords, university_college_coords, university_college_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_five University\n",
    "external_coords= np.deg2rad(top_five_university[['lat', 'lon']].values) \n",
    "external_names = top_five_university['name'].values \n",
    "distances_km, names = compute_all_distances(properties_coords, external_coords, external_names)\n",
    "distance_columns = [f'distance_to_{name.replace(\" \", \"_\").lower()}' for name in external_names]\n",
    "distance_df = pd.DataFrame(distances_km, columns=distance_columns, index=property_df.index)\n",
    "property_df = pd.concat([property_df, distance_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shop\n",
    "shop_coords = shop_df[['lat', 'lon']].values\n",
    "shop_names = shop_df['name'].values\n",
    "property_df['distance_to_shop'], property_df['nearest_shop_name'] = compute_nearest_distance_and_name(\n",
    "    properties_coords, shop_coords, shop_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.71307387977045"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "property_df.loc[803, 'distance_to_shop']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count of Nearby Kindergartens, Schools, Restaurants, and Entertainment within Defined Radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function calculates how many facilities are within a specified radius (in meters) of each property.\n",
    "# It converts facility coordinates to radians, uses a BallTree with the Haversine metric to find facilities within the radius, \n",
    "# and adds a new column to 'property_df' with the count of nearby facilities.\n",
    "def compute_facility_counts(property_df, properties_coords, facility_df, facility_name, radius=1000):\n",
    "\n",
    "    facility_coords= np.radians(facility_df[['lat', 'lon']].values)\n",
    "    tree = BallTree(facility_coords, metric='haversine')\n",
    "    indices = tree.query_radius(properties_coords, r=radius/6371000) \n",
    "\n",
    "    counts = [len(ind) for ind in indices]\n",
    "    property_df[f'{facility_name}_count_within_{radius}m'] = counts\n",
    "    \n",
    "    return property_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "kindergarten_df = school2_df[school2_df['amenity'] == \"kindergarten\" ]\n",
    "restaurant_bar_df = entertainments_df[entertainments_df['amenity'].isin(['restaurant', 'bar'])]\n",
    "cinema_theatre_df = entertainments_df[entertainments_df['amenity'].isin(['cinema', 'theatre'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kindergarten\n",
    "properties_df = compute_facility_counts(property_df, properties_coords, kindergarten_df, 'kindergarten', radius=1000)\n",
    "\n",
    "# Primary and Secondary School\n",
    "properties_df = compute_facility_counts(property_df, properties_coords, school1_df, 'secondary_primary_school', radius=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restaurant and bar\n",
    "properties_df = compute_facility_counts(property_df, properties_coords, restaurant_bar_df, 'restaurant_bar', radius=1000)\n",
    "\n",
    "# cinema and theatre\n",
    "properties_df = compute_facility_counts(property_df, properties_coords, cinema_theatre_df, 'cinema_theatre', radius=3000)\n",
    "\n",
    "# shop\n",
    "properties_df = compute_facility_counts(property_df, properties_coords, shop_df, 'shop', radius=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties_df = compute_facility_counts(property_df, properties_coords, park_df, 'park', radius=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['property_url', 'name', 'cost_text', 'latitude', 'longitude',\n",
       "       'bed_info', 'bath_info', 'parking', 'date_available', 'desc',\n",
       "       'post_code', 'region', 'matched_region_x',\n",
       "       'Children enrolled in a preschool or preschool program (no.)',\n",
       "       'Estimated resident population (no.)', 'Land area (ha)',\n",
       "       'Median monthly household mortgage payment ($)',\n",
       "       'Median price of established house transfers ($)',\n",
       "       'Median total income (excl. Government pensions and allowances) ($)',\n",
       "       'Median weekly household rental payment ($)', 'Number of jobs',\n",
       "       'Working age population (aged 15-64 years) (%)', 'matched_region_y',\n",
       "       'avg_crime_count', 'region_encoded', 'property_type_House',\n",
       "       'property_type_New Apartments / Off the Plan',\n",
       "       'property_type_New House & Land', 'property_type_Studio',\n",
       "       'property_type_Terrace', 'property_type_Townhouse',\n",
       "       'property_type_Villa', 'nearest_station_index', 'haversine_distance',\n",
       "       'property_coords', 'station_coords', 'nearest_station_name',\n",
       "       'property_index', 'route_distance_m', 'route_duration_s',\n",
       "       'distance_to_hospital', 'nearest_hospital_name',\n",
       "       'distance_to_police_station', 'nearest_police_station_name',\n",
       "       'distance_to_fire_station', 'nearest_fire_station_name',\n",
       "       'distance_to_university_college', 'nearest_university_college_name',\n",
       "       'distance_to_melbourne_central',\n",
       "       'distance_to_the_university_of_melbourne,_parkville_campus',\n",
       "       'distance_to_la_trobe_university_(bundoora_campus)',\n",
       "       'distance_to_monash_university,_clayton_campus',\n",
       "       'distance_to_deakin_university_-_burwood_campus', 'distance_to_shop',\n",
       "       'nearest_shop_name', 'kindergarten_count_within_1000m',\n",
       "       'secondary_primary_school_count_within_3000m',\n",
       "       'restaurant_bar_count_within_1000m',\n",
       "       'cinema_theatre_count_within_3000m', 'shop_count_within_1000m',\n",
       "       'park_count_within_1000m'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "properties_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties_df = properties_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties_df.to_csv('../../data/curated/properties_data4_new.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
