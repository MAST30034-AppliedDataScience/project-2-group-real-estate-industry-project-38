{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import json\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory for JSON files \n",
    "landing_base_directory = \"../../data/landing/domain_data\"\n",
    "\n",
    "# if you want to use the newest domain data to proceed, uncomment the line below and comment the above line.\n",
    "# landing_base_directory = \"../../data/landing/domain_data_new\"\n",
    "# Remember: using newest domain data will have different result from what we had in presentation and summary notebook!\n",
    "\n",
    "# This function reads a JSON file from the provided file name and returns the data.\n",
    "def read_json_file(file_name):\n",
    "    # Construct the full file path using the base directory\n",
    "    file_path = os.path.join(landing_base_directory, file_name)\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder '../../data/raw/domain_data' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# This block checks if a folder exists at the specified path.\n",
    "\n",
    "folder_path = '../../data/raw/domain_data'\n",
    "\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "    print(f\"Folder '{folder_path}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Folder '{folder_path}' already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "house = read_json_file(\"house.json\")\n",
    "apartment = read_json_file(\"apartment.json\")\n",
    "town_house = read_json_file(\"town_house.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criminal_file = '../../data/landing/other_data/Data_Tables_LGA_Criminal_Incidents_Year_Ending_March_2024.xlsx'\n",
    "criminal_data = pd.read_excel(criminal_file, sheet_name='Table 03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_by_region = pd.read_csv('../../data/landing/region_data/key_statistics/all_region_key_data.csv')\n",
    "# if you want to use the newest ABS region data to proceed, uncomment the line below and comment the above line.\n",
    "# data_by_region = pd.read_csv('../../data/landing/region_data/key_statistics/all_region_key_data_new.csv')\n",
    "# Remember: using newest ABS data will have different result from what we had in presentation and summary notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function converts data from JSON format into a flattened CSV structure. \n",
    "def convert_json_to_csv(data, json_file):\n",
    "    flat_data = []\n",
    "    directory = '../../data/raw/domain_data'\n",
    "\n",
    "    # It loops through each property in the JSON, extracts key details \n",
    "    for property_url, details in data.items():\n",
    "\n",
    "        bed_info = next((room for room in details['rooms'] if 'Bed' in room), 'N/A')\n",
    "        bath_info = next((room for room in details['rooms'] if 'Bath' in room), 'N/A')\n",
    "\n",
    "        flat_data.append({\n",
    "            'property_url': property_url,\n",
    "            'name': details.get('name', 'N/A'),\n",
    "            'property_type': details.get('property_type', 'N/A'),\n",
    "            'cost_text': details.get('cost_text', 'N/A'),\n",
    "            'latitude': details.get('latitude', 'N/A'),\n",
    "            'longitude': details.get('longitude', 'N/A'),\n",
    "            'bed_info': bed_info,\n",
    "            'bath_info': bath_info,\n",
    "            'parking': details.get('parking', 'N/A'),\n",
    "            'date_available': details.get('date_available', 'N/A'),\n",
    "            'desc': details.get('desc', '').strip('</')  \n",
    "        })\n",
    "\n",
    "    # saved as a CSV file\n",
    "    property_df = pd.DataFrame(flat_data)\n",
    "    file_path = os.path.join(directory, json_file)\n",
    "    property_df.to_csv(file_path, index=False)\n",
    "    print(f\"Data successfully converted to CSV and saved at {file_path}\")\n",
    "\n",
    "    return property_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully converted to CSV and saved at ../../data/raw/domain_data/house.csv\n",
      "Data successfully converted to CSV and saved at ../../data/raw/domain_data/apartment.csv\n",
      "Data successfully converted to CSV and saved at ../../data/raw/domain_data/town_house.csv\n"
     ]
    }
   ],
   "source": [
    "house_df = convert_json_to_csv(house, \"house.csv\")\n",
    "apartment_df = convert_json_to_csv(apartment, \"apartment.csv\")\n",
    "town_house_df = convert_json_to_csv(town_house, \"town_house.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block merges the DataFrames for town houses, houses, and apartments into a single DataFrame \n",
    "merged_data = pd.concat([town_house_df, house_df, apartment_df], ignore_index=True)\n",
    "merged_data.to_csv('../../data/raw/domain_data/properties_data1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get post code\n",
    "merged_data['post_code'] = merged_data['name'].str.extract(r'(\\d{4})$')\n",
    "\n",
    "# Get region \n",
    "merged_data['region'] = merged_data['name'].str.extract(r',\\s*([^,0-9]+)\\s+\\d{4}$')\n",
    "merged_data['region'] = merged_data['region'].str.replace(r'\\s*VIC\\s*$', '', regex=True)\n",
    "\n",
    "# Get numbers from the bed and bath columns\n",
    "merged_data['bed_info'] = merged_data['bed_info'].str.extract(r'(\\d+)').astype(int)\n",
    "merged_data['bath_info'] = merged_data['bath_info'].str.extract(r'(\\d+)').astype(int)\n",
    "\n",
    "# Get the number from the parking column and replace N/A with 0\n",
    "merged_data['parking'] = merged_data['parking'].str.extract(r'(\\d+)')\n",
    "merged_data['parking'] = merged_data['parking'].fillna(0).astype(int)\n",
    "\n",
    "# Get the numbers in the rent, remove non-numeric characters like \"$\" and \"weekly\", and convert them to floating-point numbers\n",
    "merged_data['cost_text'] = merged_data['cost_text'].str.extract(r'([\\d,\\.]+)').replace(',', '', regex=True).astype(float)\n",
    "\n",
    "# Take the data within the reasonable rent range\n",
    "merged_data = merged_data[merged_data['cost_text'].between(10, 5000)]\n",
    "\n",
    "merged_data = merged_data.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.to_csv('../../data/raw/domain_data/properties_data2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proprocessing ABS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the '-' symbol from the Region column\n",
    "data_by_region['Region'] = data_by_region['Region'].str.replace('-', '', regex=False)\n",
    "data_by_region['Region'] = data_by_region['Region'].str.replace('(', '', regex=False)\n",
    "data_by_region['Region'] = data_by_region['Region'].str.replace(')', '', regex=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep columns that are helpful in predicting house prices\n",
    "columns_to_keep = [\n",
    "    'Region',\n",
    "    'Children enrolled in a preschool or preschool program (no.)',\n",
    "    'Estimated resident population (no.)',\n",
    "    'Land area (ha)',\n",
    "    'Median monthly household mortgage payment ($)',\n",
    "    'Median price of established house transfers ($)',\n",
    "    'Median total income (excl. Government pensions and allowances) ($)',\n",
    "    'Median weekly household rental payment ($)',\n",
    "    'Number of jobs',\n",
    "    'Working age population (aged 15-64 years) (%)'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-numeric values\n",
    "# Converts the strings to numeric values\n",
    "# NaN values are then filled with the column's median\n",
    "data_by_region = data_by_region[columns_to_keep]\n",
    "\n",
    "for col in data_by_region.columns:\n",
    "    if col != 'Region':\n",
    "        data_by_region[col] = data_by_region[col].str.split('/').str[-1].str.strip()\n",
    "\n",
    "        data_by_region[col] = data_by_region[col].str.replace(' ', '')\n",
    "    \n",
    "        data_by_region[col] = pd.to_numeric(data_by_region[col], errors='coerce')\n",
    "        data_by_region[col].fillna(data_by_region[col].median(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_cleaned = merged_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regions that is present in data_by_region but not in merged_data_cleaned: {'Wilsons Promontory', 'Canadian  Mount Clear', 'Essendon Airport', 'Pakenham  North West', 'Endeavour Hills  North', 'Hampton Park  East', 'Mildura  South', 'Newtown Vic.', 'Moira', 'Mount Baw Baw Region', 'Malvern  Glen Iris', 'Longford  Loch Sport', 'Rochester', 'Koo Wee Rup', 'Orbost', 'Echuca', 'Phillip Island', 'Foster', 'Alps  West', 'Merbein', 'Woodend', 'Cranbourne North  West', 'Clyde North  North', 'Rushworth', 'Doreen  South', 'Moorabbin Airport', 'Kew  West', 'Healesville  Yarra Glen', 'Truganina  South West', 'Norlane', 'Wandin  Seville', 'Bright  Mount Beauty', 'Warrnambool  North', 'Yarriambiack', 'Craigieburn  Central', 'Richmond South  Cremorne', 'Creswick  Clunes', 'Traralgon  East', 'Lalor  West', 'Kinglake', 'Horsham', 'Narre Warren North', 'Ormond  Glen Huntly', 'Robinvale', 'Montrose', 'St Kilda  West', 'Glen Waverley  East', 'Otway', 'Hurstbridge', 'Berwick  North', 'Mount Waverley  North', 'Dandenong  North', 'Beaconsfield  Officer', 'Baranduda  Leneva', 'Ivanhoe East  Eaglemont', 'Stawell', 'Melbourne CBD  West', 'Research  North Warrandyte', 'French Island', 'Prahran  Windsor', 'Seymour Surrounds', 'Truganina  North', 'Romsey', 'Knoxfield  Scoresby', 'Towong', 'Grovedale  Mount Duneed', 'Braeside', 'Reservoir  South West', 'Wyndham Vale  North', 'Kurunjang  Toolern Vale', 'Yackandandah', 'The Basin', 'Bruthen  Omeo', 'Monbulk  Silvan', 'Lysterfield', 'Maryborough Surrounds', 'Gannawarra', 'Craigieburn  West', 'Noble Park North', 'Berwick  South East', 'Melton South  Weir Views', 'Moorabbin  Heatherton', 'Southbank  East', 'Mernda  South', 'Shepparton Surrounds  East', 'Rowville  North', 'Beaufort', 'Preston  East', 'Mill Park  South', 'Brunswick  South', 'Corio  Lovely Banks', 'Coburg  West', 'Mornington  East', 'Clayton  Central', 'Glenroy  West', 'Ballarat North  Invermay', 'Hawthorn  North', 'Cranbourne East  North', 'Narre Warren South  West', 'Bannockburn', 'Bunyip  Garfield', 'Yarram', 'Doncaster East  North', 'Ballarat', 'Warrnambool  South', 'Doncaster East  South', 'Delahey', 'Flora Hill  Spring Gully', 'Rosebud  McCrae', 'Clayton North  Notting Hill', 'Gladstone Park  Westmeadows', 'Narre Warren South  East', 'Tarneit  Central', 'Croydon Hills  Warranwood', 'Niddrie  Essendon West', 'Mount Dandenong  Olinda', 'Sale', 'Berwick  South West', 'Carlton North  Princes Hill', 'Wyndham Vale  South', 'Mansfield Vic.', 'Surrey Hills West  Canterbury', 'St Albans  North', 'Rowville  Central', 'Winchelsea', 'Wonthaggi  Inverloch', 'St Arnaud', 'North Geelong  Bell Park', 'Bundoora  North', 'West Footscray  Tottenham', 'Mitcham Vic.', 'Hoppers Crossing  North', 'West Wimmera', 'Ashwood  Chadstone', 'Taylors Lakes', 'Golden Plains  North', 'Bairnsdale', 'Sunbury  South', 'East Bendigo  Kennington', 'Rockbank  Mount Cottrell', 'South Yarra  West', 'Wangaratta Surrounds', 'Glenelg Vic.', 'Point Cook  North West', 'Oakleigh  Huntingdale', 'Croydon  East', 'Hawthorn  South', 'Doveton', 'Mildura Surrounds', 'Bentleigh East  South', 'Cranbourne South', 'Seymour', 'Cranbourne East  South', 'Highett West  Cheltenham', 'Lilydale  Coldstream', 'Maiden Gully', 'Preston  West', 'Mill Park  North', 'Mooroopna', 'Swan Hill', 'Clyde North  South', 'Golden Plains  South', 'Northcote  East', 'Macedon', 'Moyne  West', 'Kings Park Vic.', 'Lorne  Anglesea', 'Belgrave  Selby', 'Manor Lakes  Quandong', 'Kingsbury', 'Werribee  West', 'Nhill Region', 'Point Cook  North East', 'Shepparton  North', 'Brighton Vic.', 'Lake King', 'Irymple', 'Clarinda  Oakleigh South', 'Melbourne Airport', 'Emerald  Cockatoo', 'Loddon', 'Rutherglen', 'Shepparton  South East', 'Benalla', 'Paynesville', 'Glen Waverley  West', 'Ashburton Vic.', 'Ballarat East  Warrenheip', 'Mornington  West', 'Bendigo Surrounds  North', 'Roxburgh Park South  Somerton', 'Chelsea  Bonbeach', 'Kilmore  Broadford', 'Northcote  West', 'Bundoora  East', 'Dandenong  South', 'Keysborough  North', 'Epping  East', 'Viewbank  Yallambie', 'Bacchus Marsh Surrounds', 'Greenvale  Bulla', 'Werribee  South', 'Craigieburn  North West', 'Essendon  East', 'Eynesbury  Exford', 'Gordon Vic.', 'Burwood Vic.', 'Ararat', 'Kensington Vic.', 'St Albans  South', 'Corangamite  North', 'Mickleham  Yuroke', 'Sandringham  Black Rock', 'Lalor  East', 'Charlemont', 'Pakenham  South West', 'Sunbury  West', 'Ferntree Gully  North', 'Reservoir  North West', 'Tarneit  North', 'Warrandyte  Wonga Park', 'Geelong West  Hamlyn Heights', 'Campbellfield  Coolaroo', 'Castlemaine Surrounds', 'Doreen  North', 'White Hills  Ascot', 'Bentleigh East  North', 'Hoppers Crossing  South', 'Leongatha', 'Reservoir  South East', 'Cranbourne North  East', 'Ardeer  Albion', 'Southern Grampians', 'Glenroy  East', 'Lynbrook  Lyndhurst', 'Alexandra', 'Epping Vic.  West', 'Colac Surrounds', 'Epping  South', 'Seddon  Kingsville', 'Pakenham  North East', 'Altona Meadows', 'Tarneit  South', 'Brunswick  North', 'Trafalgar Vic.', 'Yarra Valley', 'Newcomb  Moolap', 'Seaford Vic.', 'Upper Yarra Valley', 'Maryborough Vic.', 'Bentleigh  McKinnon', 'Kew  South', 'Smythes Creek', 'Surrey Hills East  Mont Albert', 'Horsham Surrounds', 'Kangaroo Flat  Golden Square', 'Benalla Surrounds', 'Alps  East', 'Caulfield  North', 'Rowville  South', 'Hampton Park  West', 'Korumburra', 'Shepparton Surrounds  West', 'Nagambie', 'Point Cook  East', 'South Morang  South', 'Plenty  Yarrambat', 'South Morang  North', 'Glen Iris  East', 'West Melbourne  Residential', 'Mernda  North', 'Corangamite  South', 'Montmorency  Briar Hill', 'Aspendale Gardens  Waterways', 'Pakenham  South East', 'Ararat Surrounds', 'Mount Waverley  South', 'Gowanbrae', 'Lockington  Gunbower', 'Highett East  Cheltenham ', 'Alphington  Fairfield', 'Daylesford', 'Wangaratta', 'Keysborough  South', 'Red Cliffs', 'Yallourn North  Glengarry', 'Southbank West  South Wharf', 'Mordialloc  Parkdale', 'Flemington Racecourse', 'Morwell', 'Bundoora  West', 'Clifton Hill  Alphington', 'Barwon Heads  Armstrong Creek', 'Point Cook  South', 'Point Nepean', 'Narre Warren  North East', 'Donvale  Park Orchards', 'Carrum  Patterson Lakes', 'South Yarra  South', 'Reservoir  North East', 'West Melbourne  Industrial', 'Point Lonsdale  Queenscliff', 'Swan Hill Surrounds', 'Clifton Springs', 'Narre Warren  South West', 'Strathfieldsaye', 'Yea', 'Moe  Newborough', 'Edithvale  Aspendale', 'Chiltern  Indigo Valley', 'Fraser Rise  Plumpton', 'Buloke', 'Avoca', 'Heathcote', 'Craigieburn  North', 'Noble Park  East', 'Kerang', 'Wattle Glen  Diamond Creek', 'Upwey  Tecoma', 'Hastings  Somers', 'Melton', 'Sebastopol  Redan', 'Truganina  South East', 'Tarneit West  Mount Cottrell', 'Bendigo Surrounds  South', 'Castlemaine', 'Pearcedale  Tooradin', 'St Kilda  Central', 'Somerville', 'California Gully  Eaglehawk', 'Maffra', 'Ferntree Gully South  Upper Ferntree Gully', 'Rosedale', 'Mildura  North', 'Port Melbourne Industrial', 'Roxburgh Park  North', 'Cobblebank  Strathtulloh', 'Kyneton', 'Burnside', 'Wendouree  Miners Rest', 'Melbourne CBD  North', 'Hamilton Vic.', 'Heidelberg  Rosanna', 'Traralgon  West', 'Croydon  West', 'Craigieburn  South', 'Euroa', 'Noble Park  West', 'Richmond  North', 'Caulfield  South', 'Skye  Sandhurst', 'Melbourne CBD  East', 'South Yarra  North', 'Endeavour Hills  South', 'Moyne  East', 'Royal Botanic Gardens Victoria', 'Dromana', 'Essendon West  Aberfeldie', 'Werribee  East', 'Panton Hill  St Andrews', 'Coburg  East'}\n",
      "Region that is cleaned in merged_data_cleaned but not in data_by_region: {'Caulfield North', 'Heidelberg Heights', 'Essendon', 'Bentleigh', 'Essendon West', 'Cobblebank', 'Eynesbury', 'Warranwood', 'Sandhurst', 'Leneva', 'Kooyong', 'Clarinda', 'Fairfield', 'Southbank', 'South Geelong', 'Mordialloc', 'Tallangatta', 'Malvern', 'Mont Albert North', 'Mont Albert', 'Weir Views', 'Ferntree Gully', 'Bonbeach', 'Clyde North', 'Armstrong Creek', 'West Footscray', 'Sandringham', 'South Kingsville', 'Pakenham', 'Cranbourne East', 'Aberfeldie', 'Highett', 'Narre Warren South', 'Heidelberg', 'Mildura', 'Tarneit', 'Mernda', 'Peterborough', 'Moe', 'St Kilda West', 'Reservoir', 'Mickleham', 'Berwick', 'Ovens', 'Curlewis', 'Mount Duneed', 'Corio', 'Cobden', 'Canterbury', 'Ballarat East', 'Rosanna', 'Geelong West', 'Canadian', 'Cranbourne North', 'Cremorne', 'Roxburgh Park', 'Soldiers Hill', 'Point Cook', 'Manor Lakes', 'Bonshaw', 'Bellfield', 'Wendouree', 'Clyde', 'Coburg', 'West Melbourne', 'Seaford', 'South Yarra', 'Ivanhoe East', 'Merricks Beach', 'Doncaster East', 'Ballarat Central', 'Alphington', 'Safety Beach', 'Edithvale', 'Brunswick', 'Ardeer', 'Burnley', 'Kurunjang', 'Kennington', 'Brooklyn', 'Somers', 'Albanvale', 'Redan', 'Grovedale', 'Mill Park', 'Spotswood', 'Kangaroo Flat', 'Clifton Hill', 'McKinnon', 'Golden Point', 'Deepdene', 'St Albans Park', 'Traralgon', 'Glenroy', 'Mornington', 'Brighton', 'Truganina', 'Oakleigh', 'Rockbank', 'Chelsea', 'Albion', 'Hampton East', 'Mount Waverley', 'Port Fairy', 'Aintree', 'Officer', 'Beaconsfield', 'Glen Iris', 'Aspendale', 'Hawthorn', 'Queenscliff', 'Box Hill South', 'Middle Park', 'Kingsville', 'Seddon', 'Portsea', 'Lilydale', 'St Helena', 'Kew', 'Black Hill', 'McCrae', 'Bright', 'Heatherton', 'Newtown', 'South Morang', 'Newcomb', 'Donnybrook', 'Timboon', 'Wyndham Vale', 'Wonthaggi', 'Ripponlea', 'Mitcham', 'Macleod', 'Darley', 'St Kilda', 'Strathtulloh', 'Craigieburn', 'Sorrento', 'Richmond', 'Moorabbin', 'Quarry Hill', 'Lower Plenty', 'Prahran', 'Barwon Heads', 'Chadstone', 'Ormond', 'Ballan', 'Croydon Hills', 'Patterson Lakes', 'Whittington', 'Maidstone', 'Fraser Rise', 'Glen Huntly', 'Burwood', 'Oakleigh South', 'Hoppers Crossing', 'Nar Nar Goon', 'California Gully', 'Northcote', 'Baranduda', 'Donvale', 'Epping', 'Essendon North', 'Mambourin', 'Gladstone Park', 'Bonnie Brook', 'Croydon North', 'Tyabb', 'Dandenong', 'Lalor', 'St Albans', 'East Geelong', 'Diamond Creek', 'Cheltenham', 'Doreen', 'Blairgowrie', 'Scoresby', 'Surrey Hills', 'Tootgarook', 'Thomson', 'Aspendale Gardens', 'Bundoora', 'Bentleigh East', 'Notting Hill', 'Herne Hill', 'Clayton', 'Williamstown North', 'Kalkallo', 'Keysborough', 'Gardenvale', 'Warrnambool', 'Caulfield', 'Croydon', 'Oakleigh East', 'Marshall', 'Golden Square', 'Narre Warren', 'St Leonards', 'Carrum', 'New Gisborne', 'Ashwood', 'Rippleside', 'Thornhill Park', 'Bell Park', 'Longlea', 'Beveridge', 'Carlton North', 'Glen Waverley', 'Winter Valley', 'Kilsyth South', 'Windsor', 'Hampton Park', 'Princes Hill', 'Melton South', 'Werribee South', 'Caulfield South', 'Huntingdale', 'Mirboo North', 'Knoxfield', 'Rye', 'Lake Wendouree', 'Shepparton', 'Noble Park', 'Shoreham', 'Preston', 'Parkdale', 'Greenvale', 'Kensington', 'Elliminyt', 'Balaclava', 'Lynbrook', 'Lucas', 'Hamlyn Heights', 'Williams Landing', 'Baxter', 'Watsonia North', 'Black Rock', 'Niddrie', 'Heathmont', 'Melbourne', 'Endeavour Hills', 'Killara', 'Bell Post Hill', 'Lyndhurst', 'Deanside', 'Ashburton', 'Rowville', 'Newington', 'Werribee', 'Harkness'}\n"
     ]
    }
   ],
   "source": [
    "data_by_region_unique_regions = set(data_by_region['Region'].unique())\n",
    "merged_data_cleaned_unique_regions = set(merged_data_cleaned['region'].unique())\n",
    "\n",
    "# Find the difference\n",
    "diff_in_data_by_region = data_by_region_unique_regions - merged_data_cleaned_unique_regions\n",
    "diff_in_merged_data_cleaned = merged_data_cleaned_unique_regions - data_by_region_unique_regions\n",
    "\n",
    "print(f\"Regions that is present in data_by_region but not in merged_data_cleaned: {diff_in_data_by_region}\")\n",
    "print(f\"Region that is cleaned in merged_data_cleaned but not in data_by_region: {diff_in_merged_data_cleaned}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function finds the closest matching region name from a list of cleaned region names.\n",
    "def get_closest_match(region, cleaned_regions):\n",
    "    match, score = process.extractOne(region, cleaned_regions)\n",
    "    if score > 80:  \n",
    "        return match\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unmatched region: ['Smythes Creek' 'Creswick  Clunes' 'Daylesford' 'Gordon Vic.' 'Avoca'\n",
      " 'Beaufort' 'Maryborough Vic.' 'Maryborough Surrounds' 'Maiden Gully'\n",
      " 'Strathfieldsaye' 'Castlemaine' 'Castlemaine Surrounds' 'Heathcote'\n",
      " 'Kyneton' 'Woodend' 'Loddon' 'Bannockburn' 'Charlemont' 'Norlane'\n",
      " 'Clifton Springs' 'Lorne  Anglesea' 'Alexandra' 'Euroa'\n",
      " 'Kilmore  Broadford' 'Mansfield Vic.' 'Nagambie' 'Seymour'\n",
      " 'Seymour Surrounds' 'Yea' 'Benalla' 'Benalla Surrounds' 'Rutherglen'\n",
      " 'Wangaratta' 'Wangaratta Surrounds' 'Towong' 'Yackandandah'\n",
      " 'Trafalgar Vic.' 'Bairnsdale' 'Bruthen  Omeo' 'Orbost' 'Paynesville'\n",
      " 'Foster' 'French Island' 'Korumburra' 'Leongatha' 'Phillip Island'\n",
      " 'Wilsons Promontory' 'Morwell' 'Longford  Loch Sport' 'Maffra' 'Sale'\n",
      " 'Braeside' 'Viewbank  Yallambie' 'Kingsbury' 'Hurstbridge' 'Kinglake'\n",
      " 'Plenty  Yarrambat' 'Macedon' 'Romsey' 'Gowanbrae' 'Lysterfield'\n",
      " 'The Basin' 'Belgrave  Selby' 'Monbulk  Silvan' 'Montrose'\n",
      " 'Upwey  Tecoma' 'Wandin  Seville' 'Emerald  Cockatoo' 'Bunyip  Garfield'\n",
      " 'Koo Wee Rup' 'Doveton' 'Pearcedale  Tooradin' 'Delahey' 'Taylors Lakes'\n",
      " 'Dromana' 'Point Nepean' 'Somerville' 'Ararat' 'Ararat Surrounds'\n",
      " 'Horsham' 'Horsham Surrounds' 'Nhill Region' 'Stawell' 'West Wimmera'\n",
      " 'Yarriambiack' 'Irymple' 'Merbein' 'Red Cliffs' 'Buloke' 'Gannawarra'\n",
      " 'Kerang' 'Robinvale' 'Echuca' 'Lockington  Gunbower' 'Rochester'\n",
      " 'Rushworth' 'Moira' 'Mooroopna' 'Glenelg Vic.' 'Hamilton Vic.'\n",
      " 'Southern Grampians' 'Otway' 'Moyne  East' 'Moyne  West']\n"
     ]
    }
   ],
   "source": [
    "# This block applies the 'get_closest_match' function to the 'Region' column in 'data_by_region' \n",
    "data_by_region['matched_region'] = data_by_region['Region'].apply(lambda x: get_closest_match(x, merged_data_cleaned['region'].unique()))\n",
    "\n",
    "unmatched_data = data_by_region[data_by_region['matched_region'].isna()]\n",
    "print(f\"unmatched region: {unmatched_data['Region'].unique()}\")\n",
    "\n",
    "merged_final_geo = pd.merge(data_by_region, merged_data_cleaned, left_on='matched_region', right_on='region', how='left')\n",
    "merged_final_geo.drop(columns=['matched_region'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_cleaned['region'] = merged_data_cleaned['region'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The areas that not successfully matched: ['Tallangatta' 'Aintree' 'Spotswood' 'Maidstone' 'Macleod' 'Baxter'\n",
      " 'Brooklyn' 'Rippleside' 'Williams Landing' 'Whittington' 'Deanside'\n",
      " 'Marshall' 'Beveridge' 'Safety Beach' 'Darley' 'Tyabb' 'Kalkallo'\n",
      " 'Newington' 'Donnybrook' 'Heathmont' 'Tootgarook' 'Balaclava' 'Curlewis'\n",
      " 'Mambourin' 'Portsea' 'Shoreham' 'Rye' 'Burnley' 'Merricks Beach'\n",
      " 'Kooyong' 'Blairgowrie' 'Cobden' 'Elliminyt' 'Bonnie Brook'\n",
      " 'Nar Nar Goon' 'Harkness' 'Ovens' 'Peterborough' 'Longlea' 'Albanvale'\n",
      " 'Timboon' 'Bonshaw' 'Sorrento' 'Lucas' 'Ripponlea' 'Gardenvale'\n",
      " 'Lower Plenty' 'Deepdene']\n"
     ]
    }
   ],
   "source": [
    "# Adds a new column for merged_data_cleaned, storing the fuzzy matched region name\n",
    "merged_data_cleaned['matched_region'] = merged_data_cleaned['region'].apply(lambda x: get_closest_match(x, data_by_region['Region'].unique()))\n",
    "\n",
    "# View data that is not successfully matched\n",
    "unmatched_data = merged_data_cleaned[merged_data_cleaned['matched_region'].isna()]\n",
    "print(f\"The areas that not successfully matched: {unmatched_data['region'].unique()}\")\n",
    "\n",
    "# Merge two data sets using fuzzy matched region names\n",
    "merged_final = pd.merge(merged_data_cleaned, data_by_region, left_on='matched_region', right_on='Region', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_final_geo.to_csv('../../data/raw/domain_data/merged_final_geo.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Criminal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep column we need\n",
    "columns_to_keep = ['Year', 'Year ending', 'Local Government Area', 'Postcode', 'Suburb/Town Name', 'Offence Division']\n",
    "criminal_data = criminal_data[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_filtered = criminal_data[criminal_data['Year'].between(2020, 2024)]\n",
    "\n",
    "# Calculate the annual number of crimes based on Postcode\n",
    "crime_avg_by_postcode = crime_filtered.groupby('Postcode').size().div(5).reset_index(name='avg_crime_count')\n",
    "\n",
    "merged_final['post_code'] = merged_final['post_code'].astype(str)\n",
    "crime_avg_by_postcode['Postcode'] = crime_avg_by_postcode['Postcode'].astype(str)\n",
    "\n",
    "# Merge the average annual crime count into merged_data_cleaned\n",
    "merged_final = pd.merge(merged_final, crime_avg_by_postcode, left_on='post_code', right_on='Postcode', how='left')\n",
    "\n",
    "# Delete redundant Postcode columns\n",
    "merged_final.drop('Postcode', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2958, 26)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder path\n",
    "folder_path = '../../data/raw/other_data'\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# Save the CSV file to the newly created folder\n",
    "criminal_data.to_csv(f'{folder_path}/criminal_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types and their column counts:\n",
      "float64    13\n",
      "object     10\n",
      "int64       3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "type_counts = merged_final.dtypes.value_counts()\n",
    "print(\"Data types and their column counts:\")\n",
    "print(type_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique categories for each column in columns_to_modify:\n",
      "property_type      8\n",
      "Region           291\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "columns_to_modify = ['property_type', 'Region']\n",
    "category_counts = merged_final[columns_to_modify].nunique()\n",
    "print(\"Number of unique categories for each column in columns_to_modify:\")\n",
    "print(category_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding for region\n",
    "label_encoder = LabelEncoder()\n",
    "merged_final['region_encoded'] = label_encoder.fit_transform(merged_final['Region'])\n",
    "merged_final = merged_final.drop(columns=[\"Region\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding for property_type\n",
    "merged_final = pd.get_dummies(merged_final, columns=['property_type'], prefix='property_type', drop_first=True)\n",
    "property_type_columns = [col for col in merged_final.columns if 'property_type_' in col]\n",
    "merged_final[property_type_columns] = merged_final[property_type_columns].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative approach \n",
    "# diff_property_url_in_merged = ~merged_final['property_url'].isin(property_df0['property_url'])\n",
    "# diff_index_in_merged = merged_final[diff_property_url_in_merged].index\n",
    "# merged_final_test_cleaned = merged_final.drop(diff_index_in_merged)\n",
    "# merged_final_test_cleaned_sorted = merged_final_test_cleaned.set_index('property_url').reindex(property_df0['property_url']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_final = merged_final.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2843, 32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_final.to_csv('../../data/curated/properties_data3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
